{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVBSSYWFMPZ8"
      },
      "source": [
        "Opencv.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NimBiBewgwo"
      },
      "source": [
        "Steps:\n",
        "1.1. Installation and Set-up\n",
        "1.2. Loading an Image\n",
        "1.3. Displaying an Image\n",
        "1.4. Resizing an Image\n",
        "1.5. Rotating an Image\n",
        "\n",
        "2. Image manipulation\n",
        "\n",
        "3. Camera and Video capture\n",
        "\n",
        "4. Drawing -- Lines, Images, circles, and Text\n",
        "\n",
        "5. Colour and Colour detection\n",
        "\n",
        "6. Corner Detection\n",
        "\n",
        "7. Template matching (Object detection)\n",
        "\n",
        "8. Face and Eye detection or Tracking\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCt4-_CFR9zG"
      },
      "source": [
        "pip install caer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_qVGFZFZVec"
      },
      "source": [
        "pip install canaro"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4AeQbH2Zu_n"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkeuBZ4dvSBJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au7QCq6MZVhu"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/park.jpg')\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c5A4cdtZVng"
      },
      "source": [
        "# Converting to grayscale\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPqM7iKyZVqm"
      },
      "source": [
        "# Blur \n",
        "blur = cv.GaussianBlur(img, (7,7), cv.BORDER_DEFAULT)\n",
        "cv2_imshow(blur)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoH_cW0IZVte"
      },
      "source": [
        "# Edge Cascade\n",
        "canny = cv.Canny(blur, 125, 175)\n",
        "cv2_imshow(canny)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCGXwLykZVwj"
      },
      "source": [
        "# Dilating the image\n",
        "dilated = cv.dilate(canny, (7,7), iterations=3)\n",
        "cv2_imshow(dilated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yFpbZ3edvCe"
      },
      "source": [
        "# Eroding\n",
        "eroded = cv.erode(dilated, (7,7), iterations=3)\n",
        "cv2_imshow(eroded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH_0dAiAdvP2"
      },
      "source": [
        "# Resize\n",
        "resized = cv.resize(img, (500,500), interpolation=cv.INTER_CUBIC)\n",
        "cv2_imshow(resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1F-w9Dgd3cU"
      },
      "source": [
        "# Cropping\n",
        "cropped = img[50:200, 200:400]\n",
        "cv2_imshow(cropped)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWbFrH1ZgoSq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9OfHDpdgpQK"
      },
      "source": [
        "CONTOURS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncvVLoWzd3fd"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/cats.jpg')\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIWBzpgOd3ii"
      },
      "source": [
        "blank = np.zeros(img.shape, dtype='uint8')\n",
        "cv2_imshow( blank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nf2pL8fd3lM"
      },
      "source": [
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow( gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQmFSkWd3oD"
      },
      "source": [
        "blur = cv.GaussianBlur(gray, (5,5), cv.BORDER_DEFAULT)\n",
        "cv2_imshow(blur)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdsUaeqqd3w8"
      },
      "source": [
        "canny = cv.Canny(blur, 125, 175)\n",
        "cv2_imshow(canny)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWyobi-qd30R"
      },
      "source": [
        "ret, thresh = cv.threshold(gray, 125, 255, cv.THRESH_BINARY)\n",
        "cv2_imshow(thresh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_JxCJGid33F"
      },
      "source": [
        "contours, hierarchies = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
        "#A contour is a curve or line joining all points which have the same colour or intensity. \n",
        "#Contours help us find the points which lie on the same plane and assist in edge detection\n",
        "\n",
        "#Edge detection is used to find the boundaries of an image by finding inconsistencies in brightness. It is used for image segmentation and data extraction\n",
        "\n",
        "print(f'{len(contours)} contour(s) found!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLebjD27d358"
      },
      "source": [
        "cv.drawContours(blank, contours, -1, (0,0,255), 1)\n",
        "cv2_imshow(blank)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwEyORfkd381"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z43GMnkhgtbz"
      },
      "source": [
        "DRAW\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbHL4B_sd3vu"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "blank = np.zeros((500,500,3), dtype='uint8')\n",
        "cv2_imshow(blank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4ef3MQLg-OA"
      },
      "source": [
        "# 1. Paint the image a certain colour\n",
        "blank[200:300, 300:400] = 0,0,255\n",
        "cv2_imshow(blank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mQ1OGwgg-Re"
      },
      "source": [
        "# 2. Draw a Rectangle\n",
        "cv.rectangle(blank, (0,0), (blank.shape[1]//2, blank.shape[0]//2), (0,255,0), thickness=-1)\n",
        "cv2_imshow(blank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF9SwmYlg-Uf"
      },
      "source": [
        "# 3. Draw A circle\n",
        "cv.circle(blank, (blank.shape[1]//2, blank.shape[0]//2), 40, (0,0,255), thickness=-1)\n",
        "cv2_imshow(blank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oksgY-Fg-XZ"
      },
      "source": [
        "# 4. Draw a line\n",
        "cv.line(blank, (100,250), (300,400), (255,255,255), thickness=3) # cv.line(source_Image, starting_Position, Ending_Position, colour, Line_thickness) \n",
        "cv2_imshow( blank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz-18qUsg-aO"
      },
      "source": [
        "# 5. Write text\n",
        "cv.putText(blank, 'Hello, my name is Jason!!!', (0,225), cv.FONT_HERSHEY_TRIPLEX, 1.0, (0,255,0), 2) \n",
        "#cv.putText(image, text, center_position, font, font_scale, colour, line_thinkness, line_type)\n",
        "cv2_imshow(blank)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbP9xOtwg-c_"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X9HpIc5hhWg"
      },
      "source": [
        "IMP: READ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlGIFQBYg-f-"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/cats.jpg')\n",
        "cv2_imshow(img)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFWgCfEMg-i2"
      },
      "source": [
        "# Reading Videos\n",
        "# capture = cv.VideoCapture('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Videos/dog.mp4')\n",
        "\n",
        "# while True:\n",
        "#     isTrue, frame = capture.read()\n",
        "    \n",
        "#     cv2_imshow( frame)\n",
        "\n",
        "#     if cv.waitKey(20) & 0xFF==ord('d'):\n",
        "#         break\n",
        "\n",
        "# capture.release()\n",
        "# cv.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxqjoSpOkC3K"
      },
      "source": [
        "THRESHOLDING\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7_8bopHg-oy"
      },
      "source": [
        "#A method of image segmentation.\n",
        "# It is used to convert an image by binary by setting a threshold intensity value and deeming all values above it as 1 (convetde to white) and below as 0 (black)\n",
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/cats.jpg')\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQX6CyyEg-rf"
      },
      "source": [
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQPXrMuVs_lr"
      },
      "source": [
        "# Simple Thresholding\n",
        "threshold, thresh = cv.threshold(gray, 225, 255, cv.THRESH_BINARY )\n",
        "cv2_imshow(thresh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J7eCDyTs_pw"
      },
      "source": [
        "threshold, thresh_inv = cv.threshold(gray, 150, 255, cv.THRESH_BINARY_INV )\n",
        "cv2_imshow(thresh_inv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wGI3fuGs_wM"
      },
      "source": [
        "# Adaptive Thresholding\n",
        "adaptive_thresh = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 9)\n",
        "cv2_imshow(adaptive_thresh)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWX4kKtks_tW"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OVEj6MimCNq"
      },
      "source": [
        "IMP: TRANSFORMATIONS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54JWgct-g-uj"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/park.jpg')\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBEay-BNg-xV"
      },
      "source": [
        "# Translation\n",
        "def translate(img, x, y):\n",
        "    transMat = np.float32([[1,0,x],[0,1,y]])\n",
        "    dimensions = (img.shape[1], img.shape[0])\n",
        "    return cv.warpAffine(img, transMat, dimensions)\n",
        "\n",
        "# -x --> Left\n",
        "# -y --> Up\n",
        "# x --> Right\n",
        "# y --> Down\n",
        "\n",
        "translated = translate(img, -100, 100)\n",
        "cv2_imshow( translated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u23JmC2g-1E"
      },
      "source": [
        "# Rotation\n",
        "def rotate(img, angle, rotPoint=None):\n",
        "    (height,width) = img.shape[:2]\n",
        "\n",
        "    if rotPoint is None:\n",
        "        rotPoint = (width//2,height//2)\n",
        "    \n",
        "    rotMat = cv.getRotationMatrix2D(rotPoint, angle, 1.0)\n",
        "    dimensions = (width,height)\n",
        "\n",
        "    return cv.warpAffine(img, rotMat, dimensions)\n",
        "\n",
        "rotated = rotate(img, -45)\n",
        "cv2_imshow(rotated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jDe0GMvg-3t"
      },
      "source": [
        "rotated_rotated = rotate(img, -90)\n",
        "cv2_imshow(rotated_rotated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N47pvOoEg-67"
      },
      "source": [
        "# Resizing\n",
        "resized = cv.resize(img, (500,500), interpolation=cv.INTER_CUBIC)\n",
        "cv2_imshow(resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hej9nHNg-92"
      },
      "source": [
        "# Flipping\n",
        "flip = cv.flip(img, -1) #0 vertically, 1 both vertically and horizontally\n",
        "cv2_imshow(flip)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYiGWHCog_BE"
      },
      "source": [
        "# Cropping\n",
        "cropped = img[200:400, 300:400]\n",
        "cv2_imshow( cropped)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPKgcIFOg_D7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNJrBNZN0c_R"
      },
      "source": [
        "BITWISE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu-8SRqjg_Jm"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "blank = np.zeros((400,400), dtype='uint8')\n",
        "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1) # cv.rectangle(source_Image, center_Position, Radius, colour, Line_Thickness)\n",
        "circle = cv.circle(blank.copy(), (200,200), 200, 255, -1) #cv.circle(source_Image, center_Position, Radius, colour, Line_Thickness)\n",
        "cv2_imshow(rectangle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMgP5w8Ng_NW"
      },
      "source": [
        "cv2_imshow(circle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnDOJyqlg_Ts"
      },
      "source": [
        "# bitwise AND --> intersecting regions\n",
        "bitwise_and = cv.bitwise_and(rectangle, circle)\n",
        "cv2_imshow( bitwise_and)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOT9gG4eg_WX"
      },
      "source": [
        "# bitwise OR --> non-intersecting and intersecting regions\n",
        "bitwise_or = cv.bitwise_or(rectangle, circle)\n",
        "cv2_imshow(bitwise_or)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycTsWFOcg_Ze"
      },
      "source": [
        "# bitwise XOR --> non-intersecting regions\n",
        "bitwise_xor = cv.bitwise_xor(rectangle, circle)\n",
        "cv2_imshow( bitwise_xor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFJlAs60g_fh"
      },
      "source": [
        "# bitwise NOT\n",
        "bitwise_not = cv.bitwise_not(circle)\n",
        "cv2_imshow(bitwise_not)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoQR-CD-g_ll"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbAGYQxd1CD1"
      },
      "source": [
        "BLURRING\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W5dahdTg_jd"
      },
      "source": [
        "#Blurring is a method used to remove noise from an image by applying a low pass filter over an image. We smooth out the edges and make the transition from one colour to another very smooth\n",
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/cats.jpg')\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozSYcolDg_dW"
      },
      "source": [
        "# Averaging\n",
        "average = cv.blur(img, (3,3)) # higher the value, higher will be the blur e.g. from (3,3) to (7,7)\n",
        "cv2_imshow(average)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZGZlWLAg_RF"
      },
      "source": [
        "# Gaussian Blur: Weighted method\n",
        "gauss = cv.GaussianBlur(img, (3,3), 0)\n",
        "cv2_imshow( gauss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPjlJLb5g_Hf"
      },
      "source": [
        "# Median Blur Better in removing if there is any noise in the image\n",
        "median = cv.medianBlur(img, 3)\n",
        "cv2_imshow(median)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzrcI97Sd3tx"
      },
      "source": [
        "# Bilateral: Retain edges -- BEST method\n",
        "bilateral = cv.bilateralFilter(img, 10, 35, 25)\n",
        "cv2_imshow(bilateral)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnsXe5cs1rHg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7D3pe5t1yZB"
      },
      "source": [
        "COLOUR SPACES\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7jfEImv1rS6"
      },
      "source": [
        "#Colour spaces are a way to represent the colour channels present in an image. They tell us the various colour channels which are contributing to a particular hue\n",
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/park.jpg')\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDE8xARJ1rWK"
      },
      "source": [
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vx0v2ox1rcY"
      },
      "source": [
        "# BGR to Grayscale\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow( gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubh_FRsS1rh9"
      },
      "source": [
        "# BGR to HSV (HSV = Hue Saturation and Lightness/Brightness)\n",
        "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
        "cv2_imshow(hsv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_a30Y9c1rni"
      },
      "source": [
        "# BGR to L*a*b\n",
        "lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
        "cv2_imshow( lab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dqiZGDc1rzk"
      },
      "source": [
        "# BGR to RGB\n",
        "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "cv2_imshow(rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWBgdwY41sTl"
      },
      "source": [
        "# HSV to BGR\n",
        "lab_bgr = cv.cvtColor(lab, cv.COLOR_LAB2BGR)\n",
        "cv2_imshow(lab_bgr)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe5onw5W1sZF"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEPTVI2P2cyh"
      },
      "source": [
        "Gradients\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN-46WqV1sQ2"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/park.jpg')\n",
        "cv2_imshow( img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czmxB_2r1sNw"
      },
      "source": [
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow( gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exr6HwEz1sK9"
      },
      "source": [
        "# Laplacian\n",
        "lap = cv.Laplacian(gray, cv.CV_64F)\n",
        "lap = np.uint8(np.absolute(lap))\n",
        "cv2_imshow(lap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhGS-qGo1sIL"
      },
      "source": [
        "# Sobel \n",
        "sobelx = cv.Sobel(gray, cv.CV_64F, 1, 0)\n",
        "sobely = cv.Sobel(gray, cv.CV_64F, 0, 1)\n",
        "combined_sobel = cv.bitwise_or(sobelx, sobely)\n",
        "cv2_imshow(sobelx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xERHQG8B1sFz"
      },
      "source": [
        "cv2_imshow(sobely)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfEwn63P1sBx"
      },
      "source": [
        "cv2_imshow(combined_sobel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWADJ-wy1r_c"
      },
      "source": [
        "canny = cv.Canny(gray, 150, 175)\n",
        "cv2_imshow(canny)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM-TQO_H1r9M"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQLs99rp3you"
      },
      "source": [
        "HISROGRAM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiVlfjFJ1r6U"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/cats.jpg')\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJibe9cX1r4s"
      },
      "source": [
        "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow( gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dcyKW3GKoW8"
      },
      "source": [
        "mask = cv.circle(blank, (img.shape[1]//2,img.shape[0]//2), 100, 255, -1)\n",
        "masked = cv.bitwise_and(img,img,mask=mask)\n",
        "cv2_imshow(masked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoYT5BC4xeiG"
      },
      "source": [
        "Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUA-YLdc1rwR"
      },
      "source": [
        "#In image processing, histogram typically refer to a graph of pixel intensity values. The intensity of each pixel is plotted in a histogram\n",
        "# GRayscale histogram\n",
        "gray_hist = cv.calcHist([gray], [0], mask, [256], [0,256] )\n",
        "plt.figure()\n",
        "plt.title('Grayscale Histogram')\n",
        "plt.xlabel('Bins')\n",
        "plt.ylabel('# of pixels')\n",
        "plt.plot(gray_hist)\n",
        "plt.xlim([0,256])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj0Dx6-S1ruc"
      },
      "source": [
        "#Colour Histogram\n",
        "plt.figure()\n",
        "plt.title('Colour Histogram')\n",
        "plt.xlabel('Bins')\n",
        "plt.ylabel('# of pixels')\n",
        "colors = ('b', 'g', 'r')\n",
        "for i,col in enumerate(colors):\n",
        "    hist = cv.calcHist([img], [i], mask, [256], [0,256])\n",
        "    plt.plot(hist, color=col)\n",
        "    plt.xlim([0,256])\n",
        "\n",
        "plt.show()\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUygDt8z1rr1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP_IkuKr42yK"
      },
      "source": [
        "MASKING\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_S2D2RG1rlm"
      },
      "source": [
        "#Masking is used to bring certain parts of an image into focus by lowering the definition over other parts. \n",
        "#This is done by reducing the pixel quality of other parts of the image.\n",
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/cats2.jpg')\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24pCJyde1rgX"
      },
      "source": [
        "blank = np.zeros((300,300), dtype='uint8')\n",
        "cv2_imshow( blank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH2fEz3TH5pK"
      },
      "source": [
        "import numpy as np\n",
        "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
        "cv2_imshow(blank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTVjSRQo1rZn"
      },
      "source": [
        "circle = cv.circle(blank.copy(), (img.shape[1]//2 + 45,img.shape[0]//2), 100, 255, -1)\n",
        "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
        "weird_shape = cv.bitwise_and(circle,rectangle)\n",
        "cv2_imshow(weird_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFtHoF0yOIjs"
      },
      "source": [
        "IMP: Rescale and Resize\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09FsY8Dg50UW"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/cat.jpg')\n",
        "cv2_imshow( img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-scEF5IQ50M9"
      },
      "source": [
        "# def rescaleFrame(frame, scale=0.75):\n",
        "#     # Images, Videos and Live Video\n",
        "#     width = int(frame.shape[1] * scale) #width\n",
        "#     height = int(frame.shape[0] * scale) # Height\n",
        "\n",
        "#     dimensions = (width,height)\n",
        "\n",
        "#     return cv.resize(frame, dimensions, interpolation=cv.INTER_AREA)\n",
        "\n",
        "# def changeRes(width,height):\n",
        "#     # ONLY Live video\n",
        "#     capture.set(3,width)\n",
        "#     capture.set(4,height)\n",
        "    \n",
        "# # Reading Videos\n",
        "# capture = cv.VideoCapture('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Videos/dog.mp4')\n",
        "\n",
        "# while True:\n",
        "#     isTrue, frame = capture.read()\n",
        "\n",
        "#     frame_resized = rescaleFrame(frame, scale=.2)\n",
        "    \n",
        "#     cv2_imshow( frame)\n",
        "#     cv2_imshow( frame_resized)\n",
        "\n",
        "#     if cv.waitKey(20) & 0xFF==ord('d'):\n",
        "#         break\n",
        "\n",
        "# capture.release()\n",
        "# cv.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbXOaAEz50KG"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXjpbhdmSYI6"
      },
      "source": [
        "SPLIT MERGE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryGZnoFl50FW"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/park.jpg')\n",
        "cv2_imshow( img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGkGLZWM5z-Y"
      },
      "source": [
        "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
        "b,g,r = cv.split(img)\n",
        "blue = cv.merge([b,blank,blank])\n",
        "green = cv.merge([blank,g,blank])\n",
        "red = cv.merge([blank,blank,r])\n",
        "cv2_imshow( blue)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvX1nUjlS9w-"
      },
      "source": [
        "cv2_imshow(green)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ8MRrGrS-CN"
      },
      "source": [
        "cv2_imshow(red)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI-wdDgbS-Zo"
      },
      "source": [
        "print(img.shape) #(427,640,3) = (Height, Width, Channels) and 3 channels are in order of Blue, Green and Red\n",
        "print(b.shape)\n",
        "print(g.shape)\n",
        "print(r.shape)\n",
        "merged = cv.merge([b,g,r])\n",
        "cv2_imshow(merged)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEjID_ZNS-uq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZhhB-HaY_LP"
      },
      "source": [
        "Face Detect\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T_cLSjhS-rG"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/group 1.jpg')\n",
        "cv2_imshow( img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTCrvx49S-on"
      },
      "source": [
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow( gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP-kC6ahS-lZ"
      },
      "source": [
        "haar_cascade = cv.CascadeClassifier('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/haar_face.xml')\n",
        "faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=1) # change minNeighbors to increase face count accuracy\n",
        "print(f'Number of faces found = {len(faces_rect)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yQsv24jeDRx"
      },
      "source": [
        "for (x,y,w,h) in faces_rect:\n",
        "    cv.rectangle(img, (x,y), (x+w,y+h), (0,255,0), thickness=2)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi_7fVkMmaIf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koDB8BImmaEP"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import cv2 as cv\n",
        "img = cv.imread('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Photos/Test/Test_4.jpg')\n",
        "cv2_imshow( img)\n",
        "##############\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "# cv2_imshow( gray)\n",
        "#############\n",
        "haar_cascade = cv.CascadeClassifier('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/haar_face.xml')\n",
        "faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=1) # increase/decrease minNeighbors Minimal value e.g. 1 is superb!!!\n",
        "print(f'Number of faces found = {len(faces_rect)}')\n",
        "#############\n",
        "for (x,y,w,h) in faces_rect:\n",
        "    cv.rectangle(img, (x,y), (x+w,y+h), (0,255,0), thickness=2)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuRy10SegwXl"
      },
      "source": [
        "FACES TRAIN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1issO-rS-RQ"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "people = ['Ben Afflek', 'Elton John', 'Jerry Seinfield', 'Madonna', 'Mindy Kaling']\n",
        "DIR = r'/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Faces/train'\n",
        "\n",
        "haar_cascade = cv.CascadeClassifier('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/haar_face.xml')\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "def create_train():\n",
        "    for person in people:\n",
        "        path = os.path.join(DIR, person)\n",
        "        label = people.index(person)\n",
        "\n",
        "        for img in os.listdir(path):\n",
        "            img_path = os.path.join(path,img)\n",
        "\n",
        "            img_array = cv.imread(img_path)\n",
        "            gray = cv.cvtColor(img_array, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "            faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
        "\n",
        "            for (x,y,w,h) in faces_rect:\n",
        "                faces_roi = gray[y:y+h, x:x+w]\n",
        "                features.append(faces_roi)\n",
        "                labels.append(label)\n",
        "\n",
        "create_train()\n",
        "print(f'Length of Features = {len(features)}')\n",
        "print(f'Length of Labels = {len(labels)}')\n",
        "print('Training done ---------------')\n",
        "\n",
        "features = np.array(features, dtype='object')\n",
        "labels = np.array(labels)\n",
        "\n",
        "face_recognizer = cv.face.LBPHFaceRecognizer_create()\n",
        "\n",
        "# Train the Recognizer on the features list and the labels list\n",
        "face_recognizer.train(features,labels)\n",
        "\n",
        "face_recognizer.save('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/face_trained.yml')\n",
        "np.save('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/features.npy', features)\n",
        "np.save('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/labels.npy', labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr56sFqmin6J"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVHdH0PzdAke"
      },
      "source": [
        "Face Recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr7kiI0cS-hH"
      },
      "source": [
        "#pylint:disable=no-member\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "haar_cascade = cv.CascadeClassifier('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/haar_face.xml')\n",
        "\n",
        "people = ['Ben Afflek', 'Elton John', 'Jerry Seinfield', 'Madonna', 'Mindy Kaling']\n",
        "features = np.load('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/features.npy', allow_pickle=True)\n",
        "labels = np.load('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/labels.npy')\n",
        "\n",
        "face_recognizer = cv.face.LBPHFaceRecognizer_create()\n",
        "face_recognizer.read('/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/face_trained.yml')\n",
        "\n",
        "img = cv.imread(r'/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/Faces/val/elton_john/1.jpg')\n",
        "\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)\n",
        "\n",
        "# Detect the face in the image\n",
        "faces_rect = haar_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "for (x,y,w,h) in faces_rect:\n",
        "    faces_roi = gray[y:y+h,x:x+h]\n",
        "\n",
        "    label, confidence = face_recognizer.predict(faces_roi)\n",
        "    print(f'Label = {people[label]} with a confidence of {confidence}')\n",
        "\n",
        "    cv.putText(img, str(people[label]), (20,20), cv.FONT_HERSHEY_COMPLEX, 1.0, (0,255,0), thickness=2)\n",
        "    cv.rectangle(img, (x,y), (x+w,y+h), (0,255,0), thickness=2)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BeeCahjfPy2"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-5JV6WuS-Uu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-ROh685wSS9"
      },
      "source": [
        "PROJECT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RquK_xuyS-Oo"
      },
      "source": [
        "# Installing `caer` and `canaro` since they don't come pre-installed\n",
        "# Uncomment the following line:\n",
        "# !pip install --upgrade caer canaro\n",
        "\n",
        "import os\n",
        "import caer\n",
        "import canaro\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb3oGlp2w6j2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/simpsons_dataset/simpsons_dataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmtvqrKuww48"
      },
      "source": [
        "IMG_SIZE = (80,80)\n",
        "channels = 1\n",
        "char_path = r\"/content/drive/My Drive/Colab Notebooks/DeepLearning/Opencv/simpsons_dataset/simpsons_dataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE6gGFlX-x-n"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BLov3xhPAjU"
      },
      "source": [
        "# Creating a character dictionary, sorting it in descending order\n",
        "char_dict = {}\n",
        "for char in os.listdir(char_path):\n",
        "  char_dict[char] = len(os.listdir(os.path.join(char_path,char)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzoDgKWAjdq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F9MYG_APApb"
      },
      "source": [
        "# Sort in descending order\n",
        "char_dict = caer.sort_dict(char_dict, descending=True)\n",
        "char_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOe0I3GXPAuF"
      },
      "source": [
        "#  Getting the first 10 categories with the most number of images\n",
        "characters = []\n",
        "count = 0\n",
        "for i in char_dict:\n",
        "    characters.append(i[0])\n",
        "    count += 1\n",
        "    if count >= 10:\n",
        "        break\n",
        "characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76suul14x2sS"
      },
      "source": [
        "# Create the training data\n",
        "train = caer.preprocess_from_dir(char_path, characters, channels=channels, IMG_SIZE=IMG_SIZE, isShuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3XYgI-Sx2wS"
      },
      "source": [
        "# Number of training samples\n",
        "len(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhyT1xBux20B"
      },
      "source": [
        "# Visualizing the data (OpenCV doesn't display well in Jupyter notebooks)\n",
        "plt.figure(figsize=(30,30))\n",
        "plt.imshow(train[0][0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-aW89IEx23x"
      },
      "source": [
        "\n",
        "# Separating the array and corresponding labels\n",
        "featureSet, labels = caer.sep_train(train, IMG_SIZE=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiAOXfJGx269"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Normalize the featureSet ==> (0,1)\n",
        "featureSet = caer.normalize(featureSet)\n",
        "# Converting numerical labels to binary class vectors\n",
        "labels = to_categorical(labels, len(characters))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_rEANeAC9AN"
      },
      "source": [
        "# Creating train and validation data\n",
        "x_train, x_val, y_train, y_val = caer.train_val_split(featureSet, labels, val_ratio=.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj2Z60BGH9xI"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99rP19oJC9D0"
      },
      "source": [
        "# Deleting variables to save memory\n",
        "del train\n",
        "del featureSet\n",
        "del labels \n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgIsUleBC9HS"
      },
      "source": [
        "# Useful variables when training\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-FuHK9DC9J9"
      },
      "source": [
        "# Image data generator (introduces randomness in network ==> better accuracy)\n",
        "datagen = canaro.generators.imageDataGenerator()\n",
        "train_gen = datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERincSfYC9NV"
      },
      "source": [
        "\n",
        "# Create our model\n",
        "model = canaro.models.createSimpsonsModel(IMG_SIZE=IMG_SIZE, channels=channels, output_dim=len(characters), \n",
        "                                         loss='binary_crossentropy', decay=1e-7, learning_rate=0.001, momentum=0.9,\n",
        "                                         nesterov=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4562AEa-C9QZ"
      },
      "source": [
        "##### (OPTIONAL) If you solely want the model architecture, go to <https://github.com/jasmcaus/canaro/blob/master/canaro/models/simpsons.py> \n",
        "# and then uncomment the following to compile the model\n",
        "\n",
        "# # Compiling the model\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "# optimizer = SGD(lr=0.001, decay=1e-8, momentum=.9, nesterov=True)\n",
        "# model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAz0DGqjC9UH"
      },
      "source": [
        "# Training the model\n",
        "\n",
        "callbacks_list = [LearningRateScheduler(canaro.lr_schedule)]\n",
        "training = model.fit(train_gen,\n",
        "                    steps_per_epoch=len(x_train)//BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(x_val,y_val),\n",
        "                    validation_steps=len(y_val)//BATCH_SIZE,\n",
        "                    callbacks = callbacks_list)\n",
        "\n",
        "characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi7kOSzZC9Wv"
      },
      "source": [
        "\"\"\"## Testing\"\"\"\n",
        "\n",
        "test_path = r'../input/the-simpsons-characters-dataset/kaggle_simpson_testset/kaggle_simpson_testset/charles_montgomery_burns_0.jpg'\n",
        "\n",
        "img = cv.imread(test_path)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaWWos4Bx3Bj"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qett5X4WS-L8"
      },
      "source": [
        "def prepare(image):\n",
        "    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "    image = cv.resize(image, IMG_SIZE)\n",
        "    image = caer.reshape(image, IMG_SIZE, 1)\n",
        "    return image\n",
        "\n",
        "predictions = model.predict(prepare(img))\n",
        "\n",
        "# Getting class with the highest probability\n",
        "print(characters[np.argmax(predictions[0])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bms6yx-tS-J1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbEJimL4S-Gz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcccijcx5z7d"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}